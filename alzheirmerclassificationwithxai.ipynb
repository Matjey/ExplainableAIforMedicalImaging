{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import important libraries\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\n\nimport cv2\nimport itertools\nimport pathlib\nimport warnings\nfrom PIL import Image\nfrom random import randint\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n\n\nimport os\nprint(os.listdir(\"../input/alzheimerdata/Dataset\"))\n\nprint(\"TensorFlow Version:\", tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Split data folders","metadata":{}},{"cell_type":"code","source":"!pip install split-folders[full]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data form directory and split into train, test, and val\nimport splitfolders # or import splitfolders\n\nWORK_DIR = (\"../input/alzheimerdata/Dataset\")\nOUTPUT = \"dataset\" #where to store the split datasets .\n\nsplitfolders.ratio(WORK_DIR, output=OUTPUT, seed=1337, ratio=(.8, .1, .1)) # ratio of split are in order of train/val/test.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual Sample Class Size","metadata":{}},{"cell_type":"code","source":"DATA_SIZE ={'Non_Demented': 0, \n        'Mild_Demented': 0, \n        'Moderate_Demented':0,\n        'Very_Mild_Demented': 0}\n\nfor cls in os.listdir(WORK_DIR):\n    for img in os.listdir(WORK_DIR + '/' + cls):\n        DATA_SIZE[cls] =  DATA_SIZE[cls] + 1\n\nkeys = list(DATA_SIZE.keys())\nvalues = list(DATA_SIZE.values())\n  \nfig = plt.figure(figsize = (10, 5))\n \nplt.bar(keys, values, color=(0.2, 0.4, 0.6, 0.6), width = 0.4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"#Define some parameters for the loader\nCLASSES = [ 'Non',\n            'Mild',\n            'Moderate',\n            'VeryMild',\n            ]\n\n# For replicable results\nSEED  = 123\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\nIMG_SIZE = 128\n# Size of the images is (128,128)\nIMAGE_SIZE = [128, 128]\nDIM = (IMG_SIZE, IMG_SIZE)\n#Get the number of classes\nNUM_CLASSES= len(CLASSES)\n\n\n # get image lables\nlabels =dict(zip([0,1,2,3], CLASSES))\nBATCH_SIZE=6500\nprint(\"Constant variables settings complete\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Before Applying Augumentation","metadata":{}},{"cell_type":"code","source":"train_data = tf.keras.preprocessing.image_dataset_from_directory(\n\"./dataset/train\",\nseed=123,\nimage_size=DIM,\nbatch_size=BATCH_SIZE\n)\n\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(\n\"./dataset/test\",\nseed=123,\nimage_size=DIM,\nbatch_size=BATCH_SIZE\n)\n\nval_data = tf.keras.preprocessing.image_dataset_from_directory(\n\"./dataset/val\",\nseed=123,\nimage_size=DIM,\nbatch_size=BATCH_SIZE\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual Images before Augmentation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_data.take(1):\n    for i in range(12):\n        ax = plt.subplot(4, 4, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title( CLASSES[labels[i]])\n        plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Data Augmentation","metadata":{}},{"cell_type":"code","source":"# All images will be rescaled by 1./255.\nBRIGHT_RANGE = [0.8, 1.2]\nDATA_FORMAT = \"channels_last\"\nFILL_MODE = \"constant\"\nHORZ_FLIP = True,\nVERTICAL_FLIP = False,\nZOOM = [.99, 1.01]  \n\n# Generate training and test data with Image Generator\n# Create Image Data Generator for Train Set\ntrain_datagen = IDG(rescale = 1./255, \n                    brightness_range=BRIGHT_RANGE, \n                    zoom_range=ZOOM,\n                    data_format=DATA_FORMAT, \n                    fill_mode=FILL_MODE, \n                    horizontal_flip=HORZ_FLIP,\n                    )\n\n\n# Create Image Data Generator for Test/Validation Set\nval_datagen = IDG(rescale = 1./255)\n\n# Create Image Data Generator for Test/Validation Set\ntest_datagen= IDG(rescale = 1./255)\n\n\n#Loading the Images\n\"\"\"Flow training images in batches of 64 using train_datagen generator\nFlow_from_directory function lets the classifier directly \nidentify the labels from the name of the directories the image lies in\"\"\"\n\ntrain_ds = train_datagen.flow_from_directory(\n    directory=\"./dataset/train\",\n    seed=SEED,\n    target_size=DIM, \n    batch_size=BATCH_SIZE,\n)\n\ntest_ds = test_datagen.flow_from_directory(\n    directory=\"./dataset/test\",\n    seed=SEED,\n    target_size=DIM,\n    shuffle=False, #So we can later compare it with predicted values without having indexing problem \"\"\"\n    batch_size=BATCH_SIZE,\n  \n)\nval_ds = val_datagen.flow_from_directory(\n    directory=\"./dataset/val\",\n    seed=SEED,\n    target_size=DIM,\n    shuffle=False, #So we can later compare it with predicted values without having indexing problem \"\"\"\n    batch_size=BATCH_SIZE,\n  \n)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual images after agumentation","metadata":{}},{"cell_type":"code","source":"\"\"\"Let’s take a look at some of the train\n  set images that we obtained from the Data Augmentation\"\"\"\n # get image lables\nlabels =dict(zip([0,1,2,3], CLASSES))\n    \n# get a batch of images\nx,y = train_ds.next()\n    \n# display a grid of 9 images\nplt.figure(figsize=(10, 10))\nfor i in range(12):\n    ax = plt.subplot(4, 4, i + 1)\n    idx = randint(0, 5119)\n    plt.imshow(x[idx])\n    plt.axis(\"off\")\n    plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Data and Label","metadata":{}},{"cell_type":"code","source":"# Fetch the data and the labels\n\ntrain_data, train_labels = next(train_ds)\nval_data, val_labels = next(val_ds) \ntest_data, test_labels = next(test_ds)\n\n#Print dimensions of the dataset\nprint(\" Training data and shape and label dimension: \", train_data.shape, train_labels.shape)\nprint(\" Training data and shape and label dimension: \", val_data.shape, val_labels.shape)\nprint(\" Training data and shape and label dimension: \", test_data.shape, test_labels.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n#Since the classes are imbalanced we performing over-sampling of the data\n\ncounter = len(train_data)\nprint('Before smote train shape & label: ',counter, train_data.shape, train_labels.shape)\n\n# oversampling the train dataset using SMOTE\nsm = SMOTE()\n#X_train, y_train = smt.fit_resample(X_train, y_train)\ntrain_data_sm, train_labels_sm = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n\ntrain_data_sm = train_data_sm.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\n\nprint('After smote train shape & label: ', train_data_sm.shape, train_labels_sm.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checkout the data shape","metadata":{}},{"cell_type":"code","source":"#Let’s visualize sample from the training and  test data \nfrom tensorflow.keras.utils import to_categorical\nprint('Training data shape : ', train_data_sm.shape, train_labels_sm.shape)\nprint('Testing data shape : ', test_data.shape, test_labels.shape)\n#print(\"validation data and shape: \", val_data.shape, val_labels.shape)\n\n# Find the unique numbers from the train labels\nclasses = dict(zip([0,1,2,3], CLASSES))\nclasses_num = len(classes)\nprint('Total number of outputs : ', classes_num)\nprint('Output classes : ', classes)\nplt.figure(figsize=[10,5])\n\n# Display the first image in training data\nplt.subplot(121)\nplt.imshow(train_data[0,:,:], cmap='gray')\nplt.title(\"Train Ground Truth : {}\".format(train_labels[0]))\n\n \n# Display the first image in testing data\nplt.subplot(122)\nplt.imshow(test_data[0,:,:], cmap='gray')\nplt.title(\"Test Ground Truth : {}\".format(train_labels[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convolutional Neural Network Design","metadata":{}},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"#Defining a custom callback function to stop training our model when accuracy goes above 99%\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            \ncallback = MyCallback()\n\n#EarlyStopping callback to make sure model is always learning\nfrom tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)\n\n\n\n# Defining some neccessary imports\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n\ncnn4 = Sequential()\ncnn4.add(keras.layers.Input(shape=(IMG_SIZE,IMG_SIZE, 3)))\ncnn4.add(Conv2D(filters=16,kernel_size=(3,3),padding='same',activation='relu'))\ncnn4.add(MaxPooling2D(pool_size=(2, 2)))\ncnn4.add(Dropout(0.2))\n\ncnn4.add(Conv2D(filters=32,kernel_size=(3,3),padding='same', activation='relu'))\ncnn4.add(BatchNormalization())\ncnn4.add(MaxPooling2D(pool_size=(2, 2)))\ncnn4.add(Dropout(0.15))#15\n\ncnn4.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\ncnn4.add(BatchNormalization())\ncnn4.add(Dropout(0.15)) #20\n\ncnn4.add(Flatten())\n\n\ncnn4.add(Dense(128, activation='relu', kernel_initializer=\"he_normal\"))\ncnn4.add(BatchNormalization())\ncnn4.add(Dropout(0.5))\n\n\ncnn4.add(Dense(64, activation='relu'))\ncnn4.add(Dropout(0.5))\n\n\n\n# Output neuron. \ncnn4.add(Dense(NUM_CLASSES, activation='softmax'))\n\n        \n#Defining other parameters for our CNN model\nMetrics = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc'),\n           tf.keras.metrics.Precision(name='precision'),\n           tfa.metrics.F1Score(NUM_CLASSES)]\n\ncallbacks = [MyCallback]\n\ncnn4.compile(loss=\"categorical_crossentropy\",\n             optimizer = \"Adam\", metrics=Metrics)\n\ncnn4.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fit the training data to the model and validate it using the validation data\nfrom time import time\nStartTime = time()\nEPOCHS = 100\nhistory = cnn4.fit(train_data_sm, train_labels_sm, \n                   validation_data=(val_data, val_labels), \n                   callbacks=[callback],\n                   epochs=EPOCHS)\nEndTime = time()\nprint(\"{:.2f}\".format(round(EndTime-StartTime,2)/60), \"Minutes ****\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check for Overfitting","metadata":{}},{"cell_type":"code","source":"#Plotting the trend of the metrics during training\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric], )\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"#Evaluating the model on the data with 0.2drop\n\ntrain_scores = cnn4.evaluate(train_data, train_labels)\nval_scores = cnn4.evaluate(val_data, val_labels)\ntest_scores = cnn4.evaluate(test_data, test_labels)\n\nprint(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\nprint(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make pediction on trained model","metadata":{}},{"cell_type":"code","source":"#Predicting the test data\n\npred_labels = cnn4.predict(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion matrix ","metadata":{"execution":{"iopub.status.busy":"2022-08-17T12:44:36.382696Z","iopub.execute_input":"2022-08-17T12:44:36.383172Z","iopub.status.idle":"2022-08-17T12:44:36.722979Z","shell.execute_reply.started":"2022-08-17T12:44:36.383129Z","shell.execute_reply":"2022-08-17T12:44:36.721901Z"}}},{"cell_type":"code","source":"# Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Blues', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Alzheimer\\'s Disease Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize prediction on the test data","metadata":{}},{"cell_type":"code","source":"#visualize some of the prediction to made from the model\n# get image lables\nlabels =dict(zip([0,1,2,3], CLASSES))\nmapping  =dict(zip([0,1,2,3], CLASSES))\nrng = np.random.RandomState(42)\n    \n# get a batch of images\nx,y = test_ds.next()\nplt.figure(figsize=(20, 20))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    idx = rng.choice(range(len(test_data)))\n    plt.imshow(x[idx])\n    pred = cnn4.predict(x[idx:idx+1]).argmax(axis=1)[0]\n    if((mapping[np.argmax(y[idx])])==(mapping[pred])):\n        plt.title(\"Actual Target Value : {}\".format(mapping[np.argmax(y[idx])]), \n                  fontdict={'color':'green'})\n        plt.ylabel(\"Predicted Target Values : {}\".format(mapping[pred]),fontdict={'color':'blue'})\n            \n    else:\n        plt.title(\"Actual: {}\".format(mapping[np.argmax(y[idx])]))\n        plt.ylabel(\"Predicted: {}\".format(mapping[pred]),fontdict={'color':'red'})\n        plt.gca().axes.yaxis.set_ticklabels([])        \n        plt.gca().axes.xaxis.set_ticklabels([])   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explaining our model using limeExplainer","metadata":{}},{"cell_type":"code","source":"import lime\n\n#create an instance of LimeImageExplainer.\nfrom lime import lime_image\nexplainer = lime_image.LimeImageExplainer(random_state=123)\n\nexplainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Prediciton with Explainer","metadata":{}},{"cell_type":"code","source":"\"\"\"\nBelow, we have first randomly selected a sample from test data. \nThen, we have printed the actual label of data and the predicted label.\n\"\"\"\nfrom skimage.segmentation import felzenszwalb, flood_fill, flood\n\nmapping  =dict(zip([0,1,2,3], CLASSES))\n\n\nrng = np.random.RandomState(123)\nidx = rng.choice(range(len(test_data)))\n\n\nprint(\"Actual Target Value     : {}\".format(mapping[np.argmax(test_labels[idx])]))\npred = cnn4.predict(test_data[idx:idx+1]).argmax(axis=1)[0]\nprint(\"Predicted Target Values : {}\".format(mapping[pred]))\n\nexplanation = explainer.explain_instance(test_data[idx].astype('double'), cnn4.predict,\n                                         top_labels=2, hide_color=0, num_samples=123)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate image and mask","metadata":{}},{"cell_type":"code","source":"\"\"\"we generate an image and mask that has pixels contributing positively\nto the prediction highlighted. \"\"\"\nimg, mask = explanation.get_image_and_mask(np.argmax(test_labels[idx]), positive_only=True, hide_rest=True)\n\nimg.shape, mask.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visuals of pixels contributing postively","metadata":{}},{"cell_type":"code","source":"#Pixels Contributing Positively to Prediction\nfrom skimage.segmentation import mark_boundaries\nimport matplotlib.pyplot as plt\n\ndef plot_comparison(main_image, img, mask):\n    fig = plt.figure(figsize=(15,5))\n\n    ax = fig.add_subplot(141)\n    ax.imshow(main_image, cmap=\"gray\");\n    ax.set_title(\"Original Image\")\n    ax = fig.add_subplot(142)\n    ax.imshow(img);\n    ax.set_title(\"Image\")\n    ax = fig.add_subplot(143)\n    ax.imshow(mask);\n    ax.set_title(\"Mask\")\n    ax = fig.add_subplot(144)\n    ax.imshow(mark_boundaries(img, mask, color=(0,1,0)));\n    ax.set_title(\"Image+Mask Combined\");\n\nplot_comparison(test_data[idx], img, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visaul of pixels contributing negatively","metadata":{}},{"cell_type":"code","source":"#visualization showing pixels that contributes negatively to the prediction category\nimg, mask = explanation.get_image_and_mask(np.argmax(test_labels[idx]), positive_only=False, negative_only=True, hide_rest=True)\n\nimg.shape, mask.shape\n\nplot_comparison(test_data[idx], img, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explaination using segmentation","metadata":{}},{"cell_type":"code","source":"#Explain True Predictions With Segmentation Method \nfrom skimage.segmentation import felzenszwalb\n\nrng = np.random.RandomState(123)\nidx = rng.choice(range(len(test_data)))\n\nprint(\"Actual Target Value     : {}\".format(mapping[np.argmax(test_labels[idx])]))\npred = cnn4.predict(test_data[idx:idx+1]).argmax(axis=1)[0]\nprint(\"Predicted Target Values : {}\".format(mapping[pred]))\n\nexplanation = explainer.explain_instance(test_data[idx].squeeze(), cnn4.predict,\n                                         segmentation_fn=felzenszwalb, random_seed=123)\nexplanation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation positive pixels ","metadata":{}},{"cell_type":"code","source":"#Pixels Contributing Positively to Prediction\nimg, mask = explanation.get_image_and_mask(np.argmax(test_labels[idx]), positive_only=True, hide_rest=True)\n\nplot_comparison(test_data[idx], img, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation negetive pixels","metadata":{}},{"cell_type":"code","source":"#Pixels Contributing Negetively to Prediction\nimg, mask = explanation.get_image_and_mask(np.argmax(test_labels[idx]), positive_only=False, negative_only=True, hide_rest=True)\n\nplot_comparison(test_data[idx], img, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explaining wrong prediction","metadata":{}},{"cell_type":"code","source":"#Explain Wrong Prediction\nfrom skimage.segmentation import felzenszwalb\nrng = np.random.RandomState(123)\nidx = rng.choice(np.argwhere(test_labels != pred_labels).flatten())\n\nprint(\"Actual Target Value     : {}\".format(mapping[np.argmax(test_labels[idx])]))\npred = cnn4.predict(test_data[idx:idx+1]).argmax(axis=1)[0]\nprint(\"Predicted Target Values : {}\".format(mapping[pred]))\n\nexplanation = explainer.explain_instance(test_data[idx].squeeze(), cnn4.predict, \n                                         segmentation_fn=felzenszwalb, random_seed=123)\n\nexplanation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pixels Contributing Negetively to Prediction\nimg, mask = explanation.get_image_and_mask(np.argmax(test_labels[idx]), positive_only=True, hide_rest=True)\n\nplot_comparison(test_data[idx], img, mask)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Pixels Contributing Negetively to Prediction\nimg, mask = explanation.get_image_and_mask(np.argmax(test_labels[idx]), positive_only=False, negative_only=True, hide_rest=True)\nplot_comparison(test_data[idx], img, mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}